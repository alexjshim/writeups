%        File: exponential.tex
%     Created: Tue Feb 16 08:00 PM 2021 P
% Last Change: Tue Feb 16 08:00 PM 2021 P
%
\documentclass[a4paper]{article}
\usepackage[]{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}

\newtheorem{problem}{Problem}[section]

\begin{document}

\section{Notation}


$X$ random variable \\ 
$x$ instantiation of the random variable $X$ \\
$X_n$ sample of the random variable $X$ \\
$u(X_1, \ldots, X_N)$ sufficient statistic \\
$P$ the probability density function \\
$\theta$ parameterization of the distribution, generally denoted $P(x; \theta)$ in traditional statistics and $P(x \vert \theta)$ in Bayesian statistics \\
$\eta$ natural parameter \\
$Z(\eta)$ normalization factor of the unnormalized distribution\\
$g(\eta)$ inverse normalizer \\
$h(x)$ intrinsic/carrier measure
$ \left< \cdot, \cdot \right>$ inner product, assumed to be the dot product unless otherwise stated

\section{Pitman-Koopman-Dermois Theorem}

Suppose a sufficient statistic is additive: $ u(X_1,\ldots,X_N) = \sum_{n=1}^N u(X_n) $.  Furthermore, assume it is a minimal sufficient statistic, which means mathematically there exists a mapping $f$ from any other sufficient statistic to $u$.

\begin{equation}
  f( u'(X_1,\ldots,X_N) ) = u(X_1,\ldots,X_N)
  \label{}
\end{equation}

Then we can parametrize the distribution by the natural parameters, $\eta$, such that

\begin{equation}
  P( x \vert \eta) = g(\eta) h(x) e^{ \left< u(x), \eta \right>}
  \label{}
\end{equation} 

where 

\begin{equation}
  \begin{split}
    \tilde{P}(X) &:= h(x) e^{ \left< u(x), \eta \right> } \\
    Z(\eta) &:= \int h(x) e^{ \left< u(x), \eta \right> } dX \\
    g(\eta) &:= \frac{1}{Z(\eta)}
  \end{split}
  \label{}
\end{equation}

\begin{problem} 
Find a probability distribution that has a sufficient statistic, but is not an exponential family distribution.  Is it an additive sufficient statistic?
\end{problem}

\begin{problem}
  What is the difference between a normal distribution and an exponential family of distributions?
\end{problem}

The following are two more complicated distributions.  Challenge yourself to see if you can convert them to exponential family form.

\begin{problem}
  The Weibull distribution was used to model the distribution for the onset of covid cases.  \\
  The Weibull distribution has the cumulative distribution function
  \begin{equation}
    P( X \leq x \vert \lambda, k ) = \begin{cases}
      1-e^{-\left( \frac{x}{\lambda} \right)^k} &, x \geq 0 \\
      0 &, x <0
    \end{cases}
    \label{}
  \end{equation}

Express the Weibull distribution as an exponential family distribution (assume $k$ is fixed), with a sufficient statistic and natural parameters.  \\
Can we express it as an exponential family distribution it if $k$ is considered to be a parameter?
\end{problem}

\begin{problem}
  The Gumbel distribution, which is used for the Gumbel-softmax trick for backpropagating through categorical distributions, is defined as
  \begin{equation}
    \begin{split}
      P( x \vert \mu, \beta ) = \frac{1}{\beta} e^{-(z+e^{-z})}, \quad z:= \frac{x-\mu}{\beta} \\
      P( X \leq x \vert \mu, \beta ) = e^{-e^{-\frac{x-\mu}{\beta}} }
    \end{split}
    \label{Gumbel}
  \end{equation}
Is it an exponential family, and what assumptions do we have to make, if any?  If so, find a minimal sufficient statistic and natural parameters.
\end{problem}

The following are more conceptual questions.

\begin{problem}
  Bishop shows that the family of Bernoulli distributions is an exponential family (and Bernoulli is a special case of the binomial distribution).  However, there is a mistake/problem with Bishop's definition, what is it??
\end{problem}

\begin{problem}
  Give an exponential family that contains the binomial distribution (discrete distribution of n coin flips with the probability of heads being p).
\end{problem}

\begin{problem}
  Given a pdf, we $p(x \vert \theta)$, we can write $p(x) = e^{\log p( x \vert \theta)}$.  This seems to suggest any pdf can be turned into an exponential family.  But that is not quite correct.  Give conditions when this trick will and will not work.
\end{problem}

\begin{problem}
Show that an exponential family distribution satisfies the Fisher-Neyman factorization theorem

\begin{equation}
  p(x \vert \theta) = h(x) f_\theta( u(x) )
  \label{}
\end{equation}

where $h(x)$,$f_\theta$ are non-negative functions.

\end{problem}


\section{Sufficiency} 

This is a more advanced, theoretical section (as in you may want to skip this for later), which is meant to solidify our understanding of the mysterious concept of sufficiency.  An understanding of this is important for ideas about perfect and imperfect data reduction, such as Tishby's Information Bottleneck. \\


One explanation of a sufficient statistic is that it contains all relevant information about observations for inferring the parametrization.  We wish to understand what this means.

\begin{problem}
Suppose we know nothing about our data distribution, $P_{data}(X)$.  What would be an appropriate sufficient statistic?  \\
What do we need to specify beforehand before we can define a sufficient statistic?  
\end{problem}

\begin{problem}
  Suppose we have two sets of samples of size $N$, $\{x_1,\ldots,x_N\},\{x_1',\ldots,x_N'\}$ \footnote{A note on a change of notation, we will use lowercase $x_n$ for samples instead of capital $X_n$.  This is because we define our sufficient statistic through functions defined on the instantiations of the samples of the random variable.} from a normal distribution $\mathcal{N}( \mu, \sigma^2 )$, where $\sigma^2$ is known but $\mu$ is unknown.  \\
  Furthermore, suppose that we have a normal prior, $P(\mu) = \mathcal{N}(0,1)$.  \\
  The sufficient statistic is the sum of the samples, so 
\begin{equation}
  \begin{split}
    u(x_1,\ldots,x_N) = \sum_{n=1}^N x_n \\
    = \sum_{n=1}^N x_n' = u(x_1',\ldots,x_N') \\
  \end{split}
  \label{}
\end{equation}
Suppose the sufficient statistic is the same, $u(x_1,\ldots,x_N) = u(x'_1,\ldots,x'_N) = C$.  How do the posteriors compare?
\begin{equation}
  P( \mu \vert x_1,\ldots,x_N, u(x_1,\ldots,x_N) = C ) = P( \mu \vert x_1',\ldots,x_N', u(x_1',\ldots,x_N') = C ) ?
  \label{}
\end{equation}

\end{problem}

\begin{problem}
Suppose two sets of samples of size $N$, $\{x_1,\ldots,x_N\},\{x_1',\ldots,x_N'\}$, from a family of distributions parametrized by $\theta$ with sufficient statistic $u$.

Suppose $u(x_1,\ldots,x_N) = u(x_1',\ldots,x_N')$.  Can you find an example where $ \prod_n P(x_n \vert \theta) \neq \prod_n P(x'_n \vert \theta) $?
\end{problem}

\begin{problem}
  Suppose now that we now have two gaussian distributions with the same variance but different means, for example, $\mathcal{N}(-1,1)$ and $\mathcal{N}(1,1)$.  We pick with equal probability one of these distributions but without knowing which one, and then we can sample from it repeatedly. \\
Now we sample this distribution $N$ times, but we procedurally reject/discard and resample any samples with $x<0$,  sot we always end up with a total of $N$ accepted samples.

The sufficient statistic is still the mean (you can try to justify this, though it might be hard).

Can you come up with an example of $\{x_1,\ldots,x_N\}, \{x_1',\ldots,x_N'\}$ with the same sufficient statistic but different likelihoods?
\end{problem}

We can conclude

\begin{equation}
  P( x_1, \ldots, x_N \vert \theta, u(x_1,\ldots,x_N) = C ) \neq P( x_1', \ldots, x_N' \vert \theta, u(x_1',\ldots,x_N') = C )
  \label{}
\end{equation}

So sufficiency does not mean that all samples with the same sufficient statistic are equally likely.

It does not mean that a sample has the same likelihood regardless of the parametrization, that is, $ P(x_1,\ldots,x_N \vert \theta) \neq P(x_1,\ldots,x_n \vert \theta')$ (see ancillary statistic).

It does mean that the likelihood ratio of two samples with the same sufficient statistic is the same no matter what the parametrization:

\begin{equation}
  \frac{\prod_{n=1}^N P(x_n \vert \theta) }{ \prod_{n=1}^N P( x_n' \vert \theta) } = \frac{\prod_{n=1}^N P( x_n \vert \theta') }{ \prod_{n=1}^N P( x_n' \vert \theta') }
  \label{}
\end{equation}

That is, $X_1, \ldots, X_N \perp \theta \vert u(X_1, \ldots, X_N) $.

It also means that 

\begin{equation}
  \frac{\prod_{n=1}^N P(x_n \vert \theta) }{ \prod_{n=1}^N P( x_n \vert \theta') } = \frac{\prod_{n=1}^N P( x_n' \vert \theta) }{ \prod_{n=1}^N P( x_n' \vert \theta') }
  \label{}
\end{equation}

\begin{problem}
Explain what this equation means in terms of inferring the parameters given the sufficient statistic.
\end{problem}

\begin{problem}
Assuming the above, prove the Fisher-Neyman factorization theorem

\begin{equation}
  P(x \vert \theta) = h(x) f_\theta( u(x) )
  \label{Fisher-Neyman factorization theorem}
\end{equation}

where $h(x)$,$f_\theta$ are non-negative functions.
\end{problem}

\begin{problem}
Draw a (graphical) relationship between a sample, $\mathcal{D} = X_1,\ldots,X_N$, the sufficient statistic $u(x_1, \ldots, x_N)$, and the parametrization, $\theta$. 
Use a double forward arrow to indicate deterministic relationships.
\end{problem}


\section{Gradients of exponential families and statistical modeling}

\subsection{Gradients}

The first three problems are very fundamental to exponential families and machine learning, and have some level of progression.

\begin{problem}
Derive an expression for $ \nabla_\eta \log Z(\eta) $ (Hint: in terms of the sufficient statistics or expectations of sufficient statistics). \\
Derive an expression for $ \nabla_\eta \log Z(\eta) $ from the fact that $ \int P( x \vert \eta) dx = 1 $.
\end{problem}

\begin{problem}
Derive an expression for $ \nabla_\eta \nabla_\eta \log Z(\eta) $, the Hessian of the log normalizer, in terms of the expected sufficient statistics.
\end{problem}

\begin{problem}
Derive an expression for $ \nabla_\eta \log P( x \vert \eta ) $ in terms of the expected sufficient statistic. \\
Suppose we have samples $\left\{ X_1, \ldots, X_N \right\}$ from a data distribution, $P_{data}(X)$. We can define an empirical distribution by the mean of $N$ dirac delta functions, $ P_{emp}(X) = \frac{1}{N} \sum_{n=1}^N \delta(X = X_n) $. \footnote{The dirac delta function is a generalized function, which can be interpreted as a point mass: $ \int f(x) \delta( x = x_n) dx = f(x_n)$}. \\
Derive an expression for

\begin{equation}
  \nabla_\eta KL\left( P_{emp}(X) \Vert P( X \vert \eta) \right) 
  \label{}
\end{equation},
where
\begin{equation}
  KL\left( P_{emp}(X) \Vert P( X \vert \eta) \right) = \int P_{emp}(x) \log \frac{P_{emp}(x)}{P( x \vert \eta) } dx
  \label{}
\end{equation}
Hint: What is $ \nabla_\eta \int P_{emp}(x) \log P_{emp}(x) dx$? \\
Hint: Assume gradients commute with integration and addition, since they are linear operators.
\end{problem}

\subsection{Discriminative Modeling}
The next three problems are increasingly more complex versions of the same problem.  Choose one.

Assume we are maximizing log likelihood, although we would like a more information theoretic justification.  \\

A notational note, $X$ may now be a random vector of $K$ random variables, $X_1,\ldots,X_K$. \\
We can either denote samples of $X,Y$ as $\{X_1^n,\ldots,X_K^n,Y^n\}_{n=1}^N$, which is often notationally simplified into a matrix form, $\{X_{n1},\ldots,X_{nK},Y_n\}_{n=1}^N$.

\begin{problem}
  Suppose we have online samples $X^n$ of a Bernoulli distribution, $X \in \{0,1\}$, with an unknown probability $P(X = 1) = p$.  Derive an online first-order and Newton's method/second-order gradient-based update of the natural parameter of the Bernoulli distribution.
\end{problem}

\begin{problem}
  Suppose we have a online samples ${X,Y \sim P_{data}(X,Y)}$, with $X \in R^K$, $Y \in \{0,1\}$.  We model it with a logistic regression model, with weights $W = \{w_1,\ldots,w_k\}$. \\
  Show that our conditional Bernoulli distribution is equivalent to
  \begin{equation}
    P( Y = 1 \vert X, W) = \sigma( \sum_k w_k X_k )
    \label{logistic}
  \end{equation}
  What is the relationship between this equation and the exponential family canonical link function relationship, $E_{ Y \sim P(Y \vert \eta) } \left[ u(Y) \right] = \nabla_\eta \log Z(\eta) $. \\
  How would we model $Y$ with a single Bernoulli distribution?  What happens to $X$ in that model? \\
  What would we have to do in order to optimize each of the conditional distributions independently? \\
  We tie these conditional distributions with a single weight vector, $W$.  We could simply assume every data point has an equal gradient update contribution. \\
  Derive a first order and second order gradient-based update for the parameters $W$. \\
  We showed before that optimizing a log likelihood objective is equivalent to optimizing $KL\left( P_{emp}(X) \Vert P_{model}(X) \right)$, for a non-conditional distribution.  How can we interpret our conditional log likelihood objective as a KL-divergence?
\end{problem}

\begin{problem} Generalized Linear Models (GLM) \\
  Derive a gradient update $\nabla_W \mathcal{L}\left( \mathcal{D} \right)$, with a negative log likelihood loss function, $\mathcal{L}(\mathcal{D}) = \frac{\sum_{n=1}^N \log P_W(Y^n \vert X^n) }{N}$, with a discriminative model $ Y \vert X, W \in Poisson(\lambda) $, where the natural parameter of the Poisson distribution is $\eta = \sum_k w_k X_k$. \\
  How can we interpret our objective as a KL-divergence?
\end{problem}

\subsection{Convex Analysis}

The next two problems are more theoretical and are optional if you're not overly concerned about convex analysis.
\begin{problem}
Prove that $ \log Z(\eta)$ is a convex function. 
(Hint: use results from the above gradients problem)  \\
Prove that the domain of natural parameters is convex.  \\
Assuming that the covariance of the sufficient statistic is positive definite ( equivalently, that the variance constrained along any vector is positive), prove that there is a one-to-one relationship between $\eta$ and the expected sufficient statistic.
\end{problem}

\begin{problem}
Assuming the above, prove the canonical link function, $f( E_{ x \sim P( x \vert \eta) } [ u(x) ] ) = \eta $, exists and is one-to-one.
\end{problem}

\subsection{KL divergence, M-projections, and I-projections}

\begin{equation}
  KL \left( P(X) \Vert Q(X) \right) := \int P(x) \log \frac{P(x)}{Q(x)} dx
  \label{KL}
\end{equation}

\begin{problem}
What is $ KL\left( \mathcal{N} \left( \mu_1,\Sigma_1 \right) \Vert \mathcal{N} \left( \mu_2, \Sigma_2 \right) \right) $ ? \\
Derive a simplified expression for $ KL\left( P( x \vert \eta') \Vert P( x \vert \eta) \right)$ in terms of the natural parameters and expected sufficient statistics.  \\
\end{problem}

\begin{problem}
Moment matching / M-projections \\
What is 
\begin{equation}
  \nabla_\eta KL\left( P( X \vert \eta') \Vert P( X \vert \eta) \right)
  \label{}
\end{equation}
(Hint: do not use the final result of the above problem).
Using gradients / derivatives or the previous problem, derive a condition for the M-projection:

\begin{equation}
  \text{argmin}_\eta KL \left( P_{data}(X) \Vert P( X \vert \eta) \right) = \text{argmin}_\eta \int P_{data}(x) \log \frac{ P_{data}(x) }{ P( x \vert \eta) } dx
  \label{}
\end{equation}
\end{problem}

\begin{problem}
  Derive the M-projection of a probability distribution $P(X)$ on to the space of Gaussian distributions.  \\
  What if you only had samples of a Bernoulli distribution $P(X)$?  How would you estimate the M-projection?
\end{problem}

The first part of this problem is about the ``other'' KL divergence, which is used in variational inference and EM, and when using Boltzmann distributions it ties together ideas in thermodynamics and maximum entropy.

\begin{problem}
  Information projections / I-projections and thermodynamics\\
  I-projections fix the right hand side of a KL divergence and vary the left-hand side. \\
  Suppose are considering the I-projection of an exponential family distribution, over some class of distributions:
  \begin{equation}
    \text{argmin}_{Q(X) \in \mathcal{Q}} KL \left( Q(X) \Vert P( X \vert \eta) \right)
    \label{I-projection}
  \end{equation}
  Assuming $P(x \vert \eta) = g(\eta) e^{\left< u(x), \eta \right> }$, expand the expression for $KL\left( Q(X) \Vert P( X \vert \eta) \right)$ in terms of the entropy of $Q(X)$ and other terms. \\
  For a Boltzmann distribution, the sufficient statistic $u(x) := -\epsilon(x)$ is the negative energy function, $\eta := \frac{1}{T}$ is the inverse temperature, and we use $Z(\eta) = \frac{1}{g(\eta)}$.  Write out $KL \left( Q(X) \Vert P(X \vert \eta) \right)$, and use the fact that it is non-negative to write out an inequality for $- T \log Z(\eta)$. \\
  This is called the Helmholtz free energy.  When the expected energy is constrained to be constant, how does the entropy of $Q(X)$ compare to the Helmholtz free energy? \\
  For what distribution is the Helmholtz free energy maximized (called the Gibbs free energy)?  How does this relate to the maximum entropy distribution?
\end{problem}

\section{Probabilistic Graphical Models}

Undirected Markov networks are defined by $\mathcal{M} = \left( \mathcal{H}, \Phi \right) $ are defined by their undirected graph $\mathcal{H}$ and their factors, $\Phi = \{ \phi_i(D_i) \}_i$.  
The unnormalized probability distribution is called the Gibbs distribution:

\begin{equation}
  \tilde{P}_\Phi(\mathcal{X}) = \prod_i \phi_i(D_i)
  \label{Gibbs distribution}
\end{equation}

\begin{problem}
  If each of the factors is an exponential family distribution (not necessary the same family), write the joint distribution as an exponential family.  \\
\end{problem}

\begin{problem} Log-Linear PGMs
  For positive factors, we could could express themselves in terms of an energy function
  \begin{equation}
    \phi_i(D_i) = e^{ - \epsilon(D)}
    \label{EBM}
  \end{equation}
  For an energy-based model, we assume an energy function $\epsilon(D)$, but we have an additional temperature term, $e^{-\frac{\epsilon(D)}{\tau}}$. \\
  If we take the product of different energy-based models, with different temperatures, what are the sufficient statistics and the natural parameters of the joint distribution?
\end{problem}

\begin{problem}
  Express an Ising model and a restricted Boltzmann machine as a log-linear energy-based model.  What are the energies?  
\end{problem}

Expectation Propagation
\begin{problem}
  Whenever we perform a marginalization, we have to perform an integration, which is not necessarily analytic, or a conjugate prior for the next factor. \\
  Suppose $P(Z) = \mathcal{N}(\mu,\Sigma)$, and $P(X \vert Z)$ is Bernoulli (specifically it is a logistic model).  Suppose we want to approximate the posterior, $P(Z \vert X)$.  We can treat $P(X \vert Z)$ as an unnomralized distribution of $Z$, and make it conjugate to $P(Z)$.  How would we do this, using M-projections?  \\
\end{problem}

\section{Exponential families and convex optimization duality}

This section is focuses on a convex optimization perspective of exponential families and can be skipped.  It is still under construction.

The convex conjugate / Fenchel transform / Legendre-Fenchel transform is the function to a (potentially non-convex) function.

A notational note, we will use lowercase $x$ here for random variables, instead of instantiations, since we are not considering samples in this section.

\begin{equation}
  f^*( \lambda ) = \sup_{x \in X} \left( \left< \lambda, x \right> - f(x) \right)
  \label{convex conjugate}
\end{equation}

Let $G(\eta)$ be the log normalizer:

\begin{equation}
  G(\eta) = \log Z(\eta) = \int h(x) e^{ \left< u(x), \eta \right> } dx
  \label{}
\end{equation}

Then we can re-expresss the exponential family formula as

\begin{equation}
  P( x \vert \eta) = h(x) e^{ \left< u(x), \eta \right> - G(\eta) }
  \label{}
\end{equation}

Let's consider the convex conjugate of the log normalizer:

\begin{equation}
  F( \lambda ) = \sup_\eta \left( \left< \lambda, \eta \right> - G(\eta) \right)
  \label{}
\end{equation}

Problem:  
Solve for $ \nabla_\eta \left( \left< \lambda, \eta^* \right> - G(\eta) \right) = 0 $, specifically show that $ \lambda = E_{ x \sim P( x \vert \eta^*) } \left[ u(x) \right] $ .  Is this a global maximum?  

Using the above formula for $\lambda$, what is $F(\lambda)$?  

What is $\nabla_\lambda F(\lambda)$ ?  This gives us a formula for the canonical link function.

Fenchel's inequality is a direct result of the definition of the convex conjugate

\begin{equation}
  f^*( \lambda) + f(x) \leq \left< \lambda, x \right>
  \label{Fenchel's inequality}
\end{equation}

We observe that the exponential form of an exponential family resembles the term inside the convex conjugate:

\begin{equation}
  P( x \vert \eta) = h(x) e^{ \left< u(x), \eta \right> - G(\eta) } \leq h(x) e^{ F( \bar{u} ) }
  \label{}
\end{equation}

And that it is maximized when $u(x)$ is the expected sufficient statistic.  This means the mean sufficient statistic is related to its mode (disregarding $h(x)$ for now).  

Suppose we were to define an exponential family for the natural parameter:

\begin{equation}
  P( \eta \vert \lambda ) = h^*(\eta) e^{ \left< \lambda, \eta \right> - F(\lambda) }
  \label{}
\end{equation}

We can use Fenchel's inequality for $F(\lambda)$

\begin{equation}
  P( \eta \vert \lambda ) = h^*(\eta) e^{ \left< \lambda, \eta - \eta^* \right> + G(\eta) }
  \label{<++>}
\end{equation}<++>

\section{Conjugate Priors, EM and variational inference}

Bishop 2.4.2

For every exponential family of the form $P( x \vert \eta) = g(\eta) h(x) e^{ \left< u(x), \eta \right>}$, there exists a conjugate prior in the form

\begin{equation}
  P( \eta \vert \chi, \nu) = f( \chi, \nu) g(\eta)^\nu e^{ \nu \left< \eta, \chi \right> }
  \label{conjugate prior}
\end{equation}

\begin{problem}
  What is the normalized posterior distribution for $\eta$, in terms of $f,g,X,\chi,\nu$?  Also, I believe Bishop may have made a mistake later on in chapter 10.4, it should be $\chi_N = \frac{ \sum_n u(x_n) + \nu \chi}{\nu + N }$.
\end{problem}

Challenge problem
\begin{problem}
  Suppose $P(Y \vert X, W)$ is in an exponential family, and assume $\eta = W \phi(X)$.  Come up with a prior for the weights that is conjugate to this exponential family, and derive a formula for the posterior of the weights.
\end{problem}

Expectation Maximization
\begin{problem}
  Suppose $P(X \vert Z)$ is a generalized linear model and $P(Z)$ is a conjugate prior.
\begin{equation}
  \begin{split}
    P( X \vert Z; W) = g( W Z ) h(X) e^{\left< u(X), W Z \right> } \\
    P( Z \vert \chi, \nu) = f(\chi,\nu) g(Z)^\nu e^{\left< Z, \nu \chi \right> }
  \end{split}
  \label{}
\end{equation}
What is the posterior distribution, $P(Z \vert X, W, \chi, \nu)$?  \\
Maximize $W,\chi,\nu$ with respect to $W^{old},\chi^{old},\nu^{old}$.  What expressions do you need to know expectations in order to calculate this maximization?
\end{problem}

Variational Inference
\begin{problem}

\end{problem}

Dynamic Bayesian Networks

\begin{problem}
  Suppose we have a hidden markov model, where $P(X^{(n) \vert Z^{(n)}}$ is from an exponential family, and $P( Z^{(n+1)} \vert Z^{(n)} )$ is based off the conjugate prior (maybe assume it's a linear model, to be similar to Kalman filters).  Derive a forward message passing / belief propagation algorithm.
\end{problem}



\end{document}


